{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Birgit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa = pd.read_json(\"data/tokenized_qa.json.xz\")\n",
    "#jokes = pd.read_json(\"data/tokenized_jokes.json.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_json(\"data/tokenized_lemmatized_google_qa.json.xz\")\n",
    "jokes = pd.read_json(\"data/tokenized_lemmatized_jokes.json.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>[Which, is, the, most, common, use, of, opt-in...</td>\n",
       "      <td>[Which is the most common use of opt-in e-mail...</td>\n",
       "      <td>[which, is, the, most, common, use, of, opt-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How i.met your mother who is the mother? Tracy...</td>\n",
       "      <td>[How, i.met, your, mother, who, is, the, mothe...</td>\n",
       "      <td>[How i.met your mother who is the mother?, Tra...</td>\n",
       "      <td>[how, i.met, your, mother, who, is, the, mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is deputy cm of j and k? Deputy chief mini...</td>\n",
       "      <td>[Who, is, deputy, cm, of, j, and, k, ?, Deputy...</td>\n",
       "      <td>[Who is deputy cm of j and k?, Deputy chief mi...</td>\n",
       "      <td>[who, is, deputy, cm, of, j, and, k, ?, deputy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who played the bank robber in dirty harry? Dir...</td>\n",
       "      <td>[Who, played, the, bank, robber, in, dirty, ha...</td>\n",
       "      <td>[Who played the bank robber in dirty harry?, D...</td>\n",
       "      <td>[who, played, the, bank, robber, in, dirty, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What type of oxide are formed when metal combi...</td>\n",
       "      <td>[What, type, of, oxide, are, formed, when, met...</td>\n",
       "      <td>[What type of oxide are formed when metal comb...</td>\n",
       "      <td>[what, type, of, oxide, are, formed, when, met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307368</th>\n",
       "      <td>What channel is the audience network on comcas...</td>\n",
       "      <td>[What, channel, is, the, audience, network, on...</td>\n",
       "      <td>[What channel is the audience network on comca...</td>\n",
       "      <td>[what, channel, is, the, audience, network, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307369</th>\n",
       "      <td>When does the crisis of a shakespearean romanc...</td>\n",
       "      <td>[When, does, the, crisis, of, a, shakespearean...</td>\n",
       "      <td>[When does the crisis of a shakespearean roman...</td>\n",
       "      <td>[when, doe, the, crisis, of, a, shakespearean,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307370</th>\n",
       "      <td>Who plays henry mills on once upon a time? Hen...</td>\n",
       "      <td>[Who, plays, henry, mills, on, once, upon, a, ...</td>\n",
       "      <td>[Who plays henry mills on once upon a time?, H...</td>\n",
       "      <td>[who, play, henry, mill, on, once, upon, a, ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307371</th>\n",
       "      <td>Name of a body in orbit around sun. A small so...</td>\n",
       "      <td>[Name, of, a, body, in, orbit, around, sun, .,...</td>\n",
       "      <td>[Name of a body in orbit around sun., A small ...</td>\n",
       "      <td>[name, of, a, body, in, orbit, around, sun, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307372</th>\n",
       "      <td>Who played the blind girl in fantastic four? A...</td>\n",
       "      <td>[Who, played, the, blind, girl, in, fantastic,...</td>\n",
       "      <td>[Who played the blind girl in fantastic four?,...</td>\n",
       "      <td>[who, played, the, blind, girl, in, fantastic,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307373 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Which is the most common use of opt-in e-mail ...   \n",
       "1       How i.met your mother who is the mother? Tracy...   \n",
       "2       Who is deputy cm of j and k? Deputy chief mini...   \n",
       "3       Who played the bank robber in dirty harry? Dir...   \n",
       "4       What type of oxide are formed when metal combi...   \n",
       "...                                                   ...   \n",
       "307368  What channel is the audience network on comcas...   \n",
       "307369  When does the crisis of a shakespearean romanc...   \n",
       "307370  Who plays henry mills on once upon a time? Hen...   \n",
       "307371  Name of a body in orbit around sun. A small so...   \n",
       "307372  Who played the blind girl in fantastic four? A...   \n",
       "\n",
       "                                            word_tokenize  \\\n",
       "0       [Which, is, the, most, common, use, of, opt-in...   \n",
       "1       [How, i.met, your, mother, who, is, the, mothe...   \n",
       "2       [Who, is, deputy, cm, of, j, and, k, ?, Deputy...   \n",
       "3       [Who, played, the, bank, robber, in, dirty, ha...   \n",
       "4       [What, type, of, oxide, are, formed, when, met...   \n",
       "...                                                   ...   \n",
       "307368  [What, channel, is, the, audience, network, on...   \n",
       "307369  [When, does, the, crisis, of, a, shakespearean...   \n",
       "307370  [Who, plays, henry, mills, on, once, upon, a, ...   \n",
       "307371  [Name, of, a, body, in, orbit, around, sun, .,...   \n",
       "307372  [Who, played, the, blind, girl, in, fantastic,...   \n",
       "\n",
       "                                            sent_tokenize  \\\n",
       "0       [Which is the most common use of opt-in e-mail...   \n",
       "1       [How i.met your mother who is the mother?, Tra...   \n",
       "2       [Who is deputy cm of j and k?, Deputy chief mi...   \n",
       "3       [Who played the bank robber in dirty harry?, D...   \n",
       "4       [What type of oxide are formed when metal comb...   \n",
       "...                                                   ...   \n",
       "307368  [What channel is the audience network on comca...   \n",
       "307369  [When does the crisis of a shakespearean roman...   \n",
       "307370  [Who plays henry mills on once upon a time?, H...   \n",
       "307371  [Name of a body in orbit around sun., A small ...   \n",
       "307372  [Who played the blind girl in fantastic four?,...   \n",
       "\n",
       "                                                lemmatize  \n",
       "0       [which, is, the, most, common, use, of, opt-in...  \n",
       "1       [how, i.met, your, mother, who, is, the, mothe...  \n",
       "2       [who, is, deputy, cm, of, j, and, k, ?, deputy...  \n",
       "3       [who, played, the, bank, robber, in, dirty, ha...  \n",
       "4       [what, type, of, oxide, are, formed, when, met...  \n",
       "...                                                   ...  \n",
       "307368  [what, channel, is, the, audience, network, on...  \n",
       "307369  [when, doe, the, crisis, of, a, shakespearean,...  \n",
       "307370  [who, play, henry, mill, on, once, upon, a, ti...  \n",
       "307371  [name, of, a, body, in, orbit, around, sun, .,...  \n",
       "307372  [who, played, the, blind, girl, in, fantastic,...  \n",
       "\n",
       "[307373 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm on a seafood diet... I see food, and if it...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, 'm, on, a, seafood, diet, ..., I, see, foo...</td>\n",
       "      <td>[I'm on a seafood diet..., I see food, and if ...</td>\n",
       "      <td>[i, 'm, on, a, seafood, diet, ..., i, see, foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The shoe store... An Al Bundy one-liner:\\n\\nA ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, shoe, store, ..., An, Al, Bundy, one-lin...</td>\n",
       "      <td>[The shoe store... An Al Bundy one-liner:\\n\\nA...</td>\n",
       "      <td>[the, shoe, store, ..., an, al, bundy, one-lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you say to a veteran prostitute after ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[What, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>[What do you say to a veteran prostitute after...</td>\n",
       "      <td>[what, do, you, say, to, a, veteran, prostitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Confused man sees a psychiatrist A man goes to...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Confused, man, sees, a, psychiatrist, A, man,...</td>\n",
       "      <td>[Confused man sees a psychiatrist A man goes t...</td>\n",
       "      <td>[confused, man, see, a, psychiatrist, a, man, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "      <td>[teabags, have, fought, back, !, human, have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772973</th>\n",
       "      <td>Why is gambling not allowed in Africa? Because...</td>\n",
       "      <td>34</td>\n",
       "      <td>[Why, is, gambling, not, allowed, in, Africa, ...</td>\n",
       "      <td>[Why is gambling not allowed in Africa?, Becau...</td>\n",
       "      <td>[why, is, gambling, not, allowed, in, africa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772974</th>\n",
       "      <td>A man camped in a national park, and noticed M...</td>\n",
       "      <td>13</td>\n",
       "      <td>[A, man, camped, in, a, national, park, ,, and...</td>\n",
       "      <td>[A man camped in a national park, and noticed ...</td>\n",
       "      <td>[a, man, camped, in, a, national, park, ,, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772975</th>\n",
       "      <td>What does the H stand for in Jesus H Christ? [...</td>\n",
       "      <td>1</td>\n",
       "      <td>[What, does, the, H, stand, for, in, Jesus, H,...</td>\n",
       "      <td>[What does the H stand for in Jesus H Christ?,...</td>\n",
       "      <td>[what, doe, the, h, stand, for, in, jesus, h, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772976</th>\n",
       "      <td>What is the only thing a woman can say that wi...</td>\n",
       "      <td>21</td>\n",
       "      <td>[What, is, the, only, thing, a, woman, can, sa...</td>\n",
       "      <td>[What is the only thing a woman can say that w...</td>\n",
       "      <td>[what, is, the, only, thing, a, woman, can, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772977</th>\n",
       "      <td>I hope you're all getting your Walter Cronkite...</td>\n",
       "      <td>8</td>\n",
       "      <td>[I, hope, you, 're, all, getting, your, Walter...</td>\n",
       "      <td>[I hope you're all getting your Walter Cronkit...</td>\n",
       "      <td>[i, hope, you, 're, all, getting, your, walter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772978 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  score  \\\n",
       "0       I'm on a seafood diet... I see food, and if it...      1   \n",
       "1       The shoe store... An Al Bundy one-liner:\\n\\nA ...      1   \n",
       "2       What do you say to a veteran prostitute after ...      1   \n",
       "3       Confused man sees a psychiatrist A man goes to...      1   \n",
       "4       Teabags have fought back! Humans have been ens...      1   \n",
       "...                                                   ...    ...   \n",
       "772973  Why is gambling not allowed in Africa? Because...     34   \n",
       "772974  A man camped in a national park, and noticed M...     13   \n",
       "772975  What does the H stand for in Jesus H Christ? [...      1   \n",
       "772976  What is the only thing a woman can say that wi...     21   \n",
       "772977  I hope you're all getting your Walter Cronkite...      8   \n",
       "\n",
       "                                            word_tokenize  \\\n",
       "0       [I, 'm, on, a, seafood, diet, ..., I, see, foo...   \n",
       "1       [The, shoe, store, ..., An, Al, Bundy, one-lin...   \n",
       "2       [What, do, you, say, to, a, veteran, prostitut...   \n",
       "3       [Confused, man, sees, a, psychiatrist, A, man,...   \n",
       "4       [Teabags, have, fought, back, !, Humans, have,...   \n",
       "...                                                   ...   \n",
       "772973  [Why, is, gambling, not, allowed, in, Africa, ...   \n",
       "772974  [A, man, camped, in, a, national, park, ,, and...   \n",
       "772975  [What, does, the, H, stand, for, in, Jesus, H,...   \n",
       "772976  [What, is, the, only, thing, a, woman, can, sa...   \n",
       "772977  [I, hope, you, 're, all, getting, your, Walter...   \n",
       "\n",
       "                                            sent_tokenize  \\\n",
       "0       [I'm on a seafood diet..., I see food, and if ...   \n",
       "1       [The shoe store... An Al Bundy one-liner:\\n\\nA...   \n",
       "2       [What do you say to a veteran prostitute after...   \n",
       "3       [Confused man sees a psychiatrist A man goes t...   \n",
       "4       [Teabags have fought back!, Humans have been e...   \n",
       "...                                                   ...   \n",
       "772973  [Why is gambling not allowed in Africa?, Becau...   \n",
       "772974  [A man camped in a national park, and noticed ...   \n",
       "772975  [What does the H stand for in Jesus H Christ?,...   \n",
       "772976  [What is the only thing a woman can say that w...   \n",
       "772977  [I hope you're all getting your Walter Cronkit...   \n",
       "\n",
       "                                                lemmatize  \n",
       "0       [i, 'm, on, a, seafood, diet, ..., i, see, foo...  \n",
       "1       [the, shoe, store, ..., an, al, bundy, one-lin...  \n",
       "2       [what, do, you, say, to, a, veteran, prostitut...  \n",
       "3       [confused, man, see, a, psychiatrist, a, man, ...  \n",
       "4       [teabags, have, fought, back, !, human, have, ...  \n",
       "...                                                   ...  \n",
       "772973  [why, is, gambling, not, allowed, in, africa, ...  \n",
       "772974  [a, man, camped, in, a, national, park, ,, and...  \n",
       "772975  [what, doe, the, h, stand, for, in, jesus, h, ...  \n",
       "772976  [what, is, the, only, thing, a, woman, can, sa...  \n",
       "772977  [i, hope, you, 're, all, getting, your, walter...  \n",
       "\n",
       "[772978 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jokes = {}\n",
    "\n",
    "for i, row in jokes.iterrows():\n",
    "    #joke = row['joke']\n",
    "    joke = row['text']\n",
    "    if \"?\" in joke:\n",
    "        new_jokes[i] = {'text': joke, 'word_tokenize': row['word_tokenize'], 'sent_tokenize': row['sent_tokenize'], 'lemmatize': row['lemmatize'], 'score': row['score']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_jokes = pd.DataFrame(new_jokes).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you say to a veteran prostitute after ...</td>\n",
       "      <td>[What, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>[What do you say to a veteran prostitute after...</td>\n",
       "      <td>[what, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "      <td>[teabags, have, fought, back, !, human, have, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Why didn't the chicken cross the road ???  .  ...</td>\n",
       "      <td>[Why, did, n't, the, chicken, cross, the, road...</td>\n",
       "      <td>[Why didn't the chicken cross the road ???, .,...</td>\n",
       "      <td>[why, did, n't, the, chicken, cross, the, road...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What starts with E, ends with E, and has only ...</td>\n",
       "      <td>[What, starts, with, E, ,, ends, with, E, ,, a...</td>\n",
       "      <td>[What starts with E, ends with E, and has only...</td>\n",
       "      <td>[what, start, with, e, ,, end, with, e, ,, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "      <td>[teabags, have, fought, back, !, human, have, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "2  What do you say to a veteran prostitute after ...   \n",
       "4  Teabags have fought back! Humans have been ens...   \n",
       "5  Why didn't the chicken cross the road ???  .  ...   \n",
       "6  What starts with E, ends with E, and has only ...   \n",
       "7  Teabags have fought back! Humans have been ens...   \n",
       "\n",
       "                                       word_tokenize  \\\n",
       "2  [What, do, you, say, to, a, veteran, prostitut...   \n",
       "4  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "5  [Why, did, n't, the, chicken, cross, the, road...   \n",
       "6  [What, starts, with, E, ,, ends, with, E, ,, a...   \n",
       "7  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "\n",
       "                                       sent_tokenize  \\\n",
       "2  [What do you say to a veteran prostitute after...   \n",
       "4  [Teabags have fought back!, Humans have been e...   \n",
       "5  [Why didn't the chicken cross the road ???, .,...   \n",
       "6  [What starts with E, ends with E, and has only...   \n",
       "7  [Teabags have fought back!, Humans have been e...   \n",
       "\n",
       "                                           lemmatize score  \n",
       "2  [what, do, you, say, to, a, veteran, prostitut...     1  \n",
       "4  [teabags, have, fought, back, !, human, have, ...     1  \n",
       "5  [why, did, n't, the, chicken, cross, the, road...     1  \n",
       "6  [what, start, with, e, ,, end, with, e, ,, and...     1  \n",
       "7  [teabags, have, fought, back, !, human, have, ...     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412893, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_jokes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_jokes.index = list(range(question_jokes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What do you say to a veteran prostitute after ...</td>\n",
       "      <td>[What, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>[What do you say to a veteran prostitute after...</td>\n",
       "      <td>[what, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "      <td>[teabags, have, fought, back, !, human, have, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why didn't the chicken cross the road ???  .  ...</td>\n",
       "      <td>[Why, did, n't, the, chicken, cross, the, road...</td>\n",
       "      <td>[Why didn't the chicken cross the road ???, .,...</td>\n",
       "      <td>[why, did, n't, the, chicken, cross, the, road...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What starts with E, ends with E, and has only ...</td>\n",
       "      <td>[What, starts, with, E, ,, ends, with, E, ,, a...</td>\n",
       "      <td>[What starts with E, ends with E, and has only...</td>\n",
       "      <td>[what, start, with, e, ,, end, with, e, ,, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "      <td>[teabags, have, fought, back, !, human, have, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  What do you say to a veteran prostitute after ...   \n",
       "1  Teabags have fought back! Humans have been ens...   \n",
       "2  Why didn't the chicken cross the road ???  .  ...   \n",
       "3  What starts with E, ends with E, and has only ...   \n",
       "4  Teabags have fought back! Humans have been ens...   \n",
       "\n",
       "                                       word_tokenize  \\\n",
       "0  [What, do, you, say, to, a, veteran, prostitut...   \n",
       "1  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "2  [Why, did, n't, the, chicken, cross, the, road...   \n",
       "3  [What, starts, with, E, ,, ends, with, E, ,, a...   \n",
       "4  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "\n",
       "                                       sent_tokenize  \\\n",
       "0  [What do you say to a veteran prostitute after...   \n",
       "1  [Teabags have fought back!, Humans have been e...   \n",
       "2  [Why didn't the chicken cross the road ???, .,...   \n",
       "3  [What starts with E, ends with E, and has only...   \n",
       "4  [Teabags have fought back!, Humans have been e...   \n",
       "\n",
       "                                           lemmatize score  \n",
       "0  [what, do, you, say, to, a, veteran, prostitut...     1  \n",
       "1  [teabags, have, fought, back, !, human, have, ...     1  \n",
       "2  [why, did, n't, the, chicken, cross, the, road...     1  \n",
       "3  [what, start, with, e, ,, end, with, e, ,, and...     1  \n",
       "4  [teabags, have, fought, back, !, human, have, ...     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "jokes\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "datas = {}\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words.extend([\"...\", \"'s\", \"wo\", \"n't\", \"'m\", \"ca\", \"'ll\", \"'re\", \"'ve\", \"'d\", \"ha\", \"Â´Â´\", \"Â´\", \"Â´Â´Â´\", \",\", \"!\", \"?\", \"'\", \":\", \";\", '\"', \"\\\\\", \"``\"])\n",
    "\n",
    "all_lem_data = []\n",
    "for name, data, n in zip(['qa', 'jokes'], [qa, question_jokes], [100000, 100000]):\n",
    "    print(name, end=\"\\n\")\n",
    "    lemmatized_data = []\n",
    "    for i, row in data.iterrows():\n",
    "        if i == n:\n",
    "            break\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        '''text = row[\"text\"]\n",
    "        for ajaleht in ajalehed:\n",
    "            text = re.sub(ajaleht, \"\", text)\n",
    "        \n",
    "        words = word_tokenize(text)'''\n",
    "        \n",
    "        words = row['word_tokenize']\n",
    "        lemmas = []\n",
    "\n",
    "        for word in words:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            if len(lemma) > 1 and not lemma in stop_words:\n",
    "                lemmas.append(lemma.lower())\n",
    "                \n",
    "        lemmatized_row = {'id': f\"{name}_{i}\",'text': \" \".join(lemmas), 'joke': 1 if name == 'jokes' else 0}\n",
    "        lemmatized_data.append(lemmatized_row)\n",
    "        all_lem_data.append(lemmatized_row)\n",
    "    \n",
    "    datas[name] = pd.DataFrame(lemmatized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stopwords.extend([\"...\", \"'s\", \"wo\", \"n't\", \"'m\", \"ca\", \"'ll\", \"'re\", \"'ve\", \"'d\", \"ha\", \"Â´Â´\", \"Â´\", \"Â´Â´Â´\", \",\", \"!\", \"'\", \":\", \";\", '\"', \"\\\\\", \"``\"])\n",
    "stopwords.extend([\"wa\", \"''\", \"the\", \"he\", \"my\", \"it\"])\n",
    "\n",
    "data_for_df = []\n",
    "\n",
    "#jokes = list(datas['jokes'].text)\n",
    "#ids = list(datas['jokes'].id)\n",
    "jokes_lemmas = question_jokes['lemmatize']\n",
    "\n",
    "for i, joke in enumerate(jokes_lemmas):\n",
    "    #joke_words = joke.split(\" \")\n",
    "    joke_words = [word for word in joke if word not in stopwords and word.isalpha()]\n",
    "    joke_text = \" \".join(joke_words)\n",
    "    #data_for_df.append({'id': ids[i], 'text': joke_text, 'joke': 1})\n",
    "    data_for_df.append({'text': joke_text, 'joke': 1})\n",
    "    \n",
    "#qa = list(datas['qa'].text)\n",
    "#qa_ids = list(datas['qa'].id)\n",
    "qa_lemmas = qa['lemmatize']\n",
    "\n",
    "for i, q in enumerate(qa_lemmas):\n",
    "    #qa_words = q.split(\" \")\n",
    "    qa_words = [word for word in q if word not in stopwords and word.isalpha()]\n",
    "    qa_text = \" \".join(qa_words)\n",
    "    #data_for_df.append({'id': qa_ids[i], 'text': qa_text, 'joke': 0})\n",
    "    data_for_df.append({'text': qa_text, 'joke': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say veteran prostitute night together thank ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teabags fought back human enslaved civilizatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicken cross road kfc side</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start e end e letter envelope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teabags fought back human enslaved civilizatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720261</th>\n",
       "      <td>channel audience network comcast directv nbc s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720262</th>\n",
       "      <td>doe crisis shakespearean romance occur shakesp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720263</th>\n",
       "      <td>play henry mill upon time henry daniel mill fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720264</th>\n",
       "      <td>name body orbit around sun small solar system ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720265</th>\n",
       "      <td>played blind girl fantastic four alicia blind ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720266 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  joke\n",
       "0       say veteran prostitute night together thank ce...     1\n",
       "1       teabags fought back human enslaved civilizatio...     1\n",
       "2                             chicken cross road kfc side     1\n",
       "3                           start e end e letter envelope     1\n",
       "4       teabags fought back human enslaved civilizatio...     1\n",
       "...                                                   ...   ...\n",
       "720261  channel audience network comcast directv nbc s...     0\n",
       "720262  doe crisis shakespearean romance occur shakesp...     0\n",
       "720263  play henry mill upon time henry daniel mill fi...     0\n",
       "720264  name body orbit around sun small solar system ...     0\n",
       "720265  played blind girl fantastic four alicia blind ...     0\n",
       "\n",
       "[720266 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665660, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB\n",
    "Shallow model as a base to see how it works and which features are more important for predictions. It is easier to obtain from this information from a shallow model rather than a neural network, so this was used to gain some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_subdf = df[df['joke'] == 1].head(25000)\n",
    "qa_subdf = df[df['joke'] == 0].head(25000)\n",
    "\n",
    "smaller_df = pd.concat([jokes_subdf, qa_subdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say veteran prostitute night together thank ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teabags fought back human enslaved civilizatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicken cross road kfc side</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start e end e letter envelope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teabags fought back human enslaved civilizatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437901</th>\n",
       "      <td>film america got talent following america got ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437902</th>\n",
       "      <td>many season schitts creek schitt creek genre s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437903</th>\n",
       "      <td>place world michael w smith gospel music hall ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437904</th>\n",
       "      <td>eurovision song contest winner contest ukraine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437905</th>\n",
       "      <td>country southern tip africa urban food securit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  joke\n",
       "0       say veteran prostitute night together thank ce...     1\n",
       "1       teabags fought back human enslaved civilizatio...     1\n",
       "2                             chicken cross road kfc side     1\n",
       "3                           start e end e letter envelope     1\n",
       "4       teabags fought back human enslaved civilizatio...     1\n",
       "...                                                   ...   ...\n",
       "437901  film america got talent following america got ...     0\n",
       "437902  many season schitts creek schitt creek genre s...     0\n",
       "437903  place world michael w smith gospel music hall ...     0\n",
       "437904  eurovision song contest winner contest ukraine...     0\n",
       "437905  country southern tip africa urban food securit...     0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(smaller_df['text'], smaller_df['joke'], test_size=0.2, stratify=smaller_df['joke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: joke, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jokes as the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mnb.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.46416109, -11.94034073, -11.12011294, ..., -11.66017755,\n",
       "        -11.66017755, -11.66017755]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is from: https://stackoverflow.com/questions/29867367/sklearn-multinomial-nb-most-informative-features\n",
    "\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        #print (round(coef_1, 2), fn_1, \"\\t\\t\", round(coef_2, 2), fn_2)\n",
    "        print (round(coef_2, 2), fn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.72 say\n",
      "-5.81 call\n",
      "-6.03 man\n",
      "-6.07 get\n",
      "-6.28 doe\n",
      "-6.28 know\n",
      "-6.29 one\n",
      "-6.42 said\n",
      "-6.48 go\n",
      "-6.49 joke\n",
      "-6.5 guy\n",
      "-6.57 like\n",
      "-6.77 woman\n",
      "-6.78 wife\n",
      "-6.78 asks\n",
      "-6.79 asked\n",
      "-6.83 hear\n",
      "-6.84 people\n",
      "-6.85 see\n",
      "-6.86 trump\n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88485"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnb.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 88485)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-jokes as the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vect, [abs(val-1) for val in y_train.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mnb.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9537"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results == [abs(val-1) for val in y_test.values]) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.44 state\n",
      "-6.53 season\n",
      "-6.65 song\n",
      "-6.65 first\n",
      "-6.79 united\n",
      "-6.86 film\n",
      "-6.86 new\n",
      "-6.89 series\n",
      "-6.9 episode\n",
      "-6.95 year\n",
      "-6.95 world\n",
      "-7.02 american\n",
      "-7.02 also\n",
      "-7.06 time\n",
      "-7.08 one\n",
      "-7.13 may\n",
      "-7.13 doe\n",
      "-7.22 war\n",
      "-7.23 game\n",
      "-7.29 two\n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15000\n",
    "maxlen = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "tokenized_X_train = tokenizer.texts_to_sequences(X_train)\n",
    "tokenized_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(tokenized_X_train, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(tokenized_X_test, maxlen=X_train_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vec = to_categorical(y_train)\n",
    "y_test_vec = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 500) (10000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pad.shape, X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 64)           960000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 35)                14000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 72        \n",
      "=================================================================\n",
      "Total params: 974,072\n",
      "Trainable params: 974,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=num_words, input_length=X_train_pad.shape[1], output_dim=64))\n",
    "model.add(layers.LSTM(35))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initially training on a smaller subset of data to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 342s 9ms/sample - loss: 0.2049 - accuracy: 0.9111 - val_loss: 0.0760 - val_accuracy: 0.9739\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 346s 9ms/sample - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.0721 - val_accuracy: 0.9762\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 389s 10ms/sample - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0779 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e539d77c8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train_vec, validation_data=(X_test_pad, y_test_vec), epochs=3, verbose=1, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jokes_subdf = df[df['joke'] == 1].tail(5000)\n",
    "test_qa_subdf = df[df['joke'] == 0].tail(5000)\n",
    "test_smaller_df = pd.concat([test_jokes_subdf, test_qa_subdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_X = tokenizer.texts_to_sequences(test_smaller_df['text'])\n",
    "test_X_pad = pad_sequences(tokenized_test_X, maxlen=X_train_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_probs = model.predict(test_X_pad)\n",
    "predictions = [np.argmax(prob) for prob in predictions_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.91"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions == test_smaller_df['joke']) / len(predictions) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
