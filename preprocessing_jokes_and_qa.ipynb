{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Birgit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_json(\"data/tokenized_qa.json.xz\")\n",
    "jokes = pd.read_json(\"data/tokenized_jokes.json.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>[which, is, the, most, common, use, of, opt-in...</td>\n",
       "      <td>[which is the most common use of opt-in e-mail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how i.met your mother who is the mother Tracy ...</td>\n",
       "      <td>[how, i.met, your, mother, who, is, the, mothe...</td>\n",
       "      <td>[how i.met your mother who is the mother Tracy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what type of fertilisation takes place in huma...</td>\n",
       "      <td>[what, type, of, fertilisation, takes, place, ...</td>\n",
       "      <td>[what type of fertilisation takes place in hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who had the most wins in the nfl Active quarte...</td>\n",
       "      <td>[who, had, the, most, wins, in, the, nfl, Acti...</td>\n",
       "      <td>[who had the most wins in the nfl Active quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what happened to the lost settlement of roanok...</td>\n",
       "      <td>[what, happened, to, the, lost, settlement, of...</td>\n",
       "      <td>[what happened to the lost settlement of roano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307368</th>\n",
       "      <td>who have been the hosts of the price is right ...</td>\n",
       "      <td>[who, have, been, the, hosts, of, the, price, ...</td>\n",
       "      <td>[who have been the hosts of the price is right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307369</th>\n",
       "      <td>who sang the song mama told me not to come The...</td>\n",
       "      <td>[who, sang, the, song, mama, told, me, not, to...</td>\n",
       "      <td>[who sang the song mama told me not to come Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307370</th>\n",
       "      <td>who plays grey worm on game of thrones Jacob B...</td>\n",
       "      <td>[who, plays, grey, worm, on, game, of, thrones...</td>\n",
       "      <td>[who plays grey worm on game of thrones Jacob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307371</th>\n",
       "      <td>working principle of high pressure sodium vapo...</td>\n",
       "      <td>[working, principle, of, high, pressure, sodiu...</td>\n",
       "      <td>[working principle of high pressure sodium vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307372</th>\n",
       "      <td>what is the latest red hat linux version Red H...</td>\n",
       "      <td>[what, is, the, latest, red, hat, linux, versi...</td>\n",
       "      <td>[what is the latest red hat linux version Red ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307373 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       which is the most common use of opt-in e-mail ...   \n",
       "1       how i.met your mother who is the mother Tracy ...   \n",
       "2       what type of fertilisation takes place in huma...   \n",
       "3       who had the most wins in the nfl Active quarte...   \n",
       "4       what happened to the lost settlement of roanok...   \n",
       "...                                                   ...   \n",
       "307368  who have been the hosts of the price is right ...   \n",
       "307369  who sang the song mama told me not to come The...   \n",
       "307370  who plays grey worm on game of thrones Jacob B...   \n",
       "307371  working principle of high pressure sodium vapo...   \n",
       "307372  what is the latest red hat linux version Red H...   \n",
       "\n",
       "                                            word_tokenize  \\\n",
       "0       [which, is, the, most, common, use, of, opt-in...   \n",
       "1       [how, i.met, your, mother, who, is, the, mothe...   \n",
       "2       [what, type, of, fertilisation, takes, place, ...   \n",
       "3       [who, had, the, most, wins, in, the, nfl, Acti...   \n",
       "4       [what, happened, to, the, lost, settlement, of...   \n",
       "...                                                   ...   \n",
       "307368  [who, have, been, the, hosts, of, the, price, ...   \n",
       "307369  [who, sang, the, song, mama, told, me, not, to...   \n",
       "307370  [who, plays, grey, worm, on, game, of, thrones...   \n",
       "307371  [working, principle, of, high, pressure, sodiu...   \n",
       "307372  [what, is, the, latest, red, hat, linux, versi...   \n",
       "\n",
       "                                            sent_tokenize  \n",
       "0       [which is the most common use of opt-in e-mail...  \n",
       "1       [how i.met your mother who is the mother Tracy...  \n",
       "2       [what type of fertilisation takes place in hum...  \n",
       "3       [who had the most wins in the nfl Active quart...  \n",
       "4       [what happened to the lost settlement of roano...  \n",
       "...                                                   ...  \n",
       "307368  [who have been the hosts of the price is right...  \n",
       "307369  [who sang the song mama told me not to come Th...  \n",
       "307370  [who plays grey worm on game of thrones Jacob ...  \n",
       "307371  [working principle of high pressure sodium vap...  \n",
       "307372  [what is the latest red hat linux version Red ...  \n",
       "\n",
       "[307373 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm on a seafood diet... I see food, and if it...</td>\n",
       "      <td>[I, 'm, on, a, seafood, diet, ..., I, see, foo...</td>\n",
       "      <td>[I'm on a seafood diet..., I see food, and if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The shoe store... An Al Bundy one-liner:\\n\\nA ...</td>\n",
       "      <td>[The, shoe, store, ..., An, Al, Bundy, one-lin...</td>\n",
       "      <td>[The shoe store... An Al Bundy one-liner:\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you say to a veteran prostitute after ...</td>\n",
       "      <td>[What, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>[What do you say to a veteran prostitute after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Confused man sees a psychiatrist A man goes to...</td>\n",
       "      <td>[Confused, man, sees, a, psychiatrist, A, man,...</td>\n",
       "      <td>[Confused man sees a psychiatrist A man goes t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962882</th>\n",
       "      <td>At 12:01 after midnight, on a cloudy evening, ...</td>\n",
       "      <td>[At, 12:01, after, midnight, ,, on, a, cloudy,...</td>\n",
       "      <td>[At 12:01 after midnight, on a cloudy evening,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962883</th>\n",
       "      <td>Two Gay guys are lying on their bed... Two gay...</td>\n",
       "      <td>[Two, Gay, guys, are, lying, on, their, bed, ....</td>\n",
       "      <td>[Two Gay guys are lying on their bed... Two ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962884</th>\n",
       "      <td>What do scientists use to measure a chicken's ...</td>\n",
       "      <td>[What, do, scientists, use, to, measure, a, ch...</td>\n",
       "      <td>[What do scientists use to measure a chicken's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962885</th>\n",
       "      <td>What is the only thing a woman can say that wi...</td>\n",
       "      <td>[What, is, the, only, thing, a, woman, can, sa...</td>\n",
       "      <td>[What is the only thing a woman can say that w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962886</th>\n",
       "      <td>I hope you're all getting your Walter Cronkite...</td>\n",
       "      <td>[I, hope, you, 're, all, getting, your, Walter...</td>\n",
       "      <td>[I hope you're all getting your Walter Cronkit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962887 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     joke  \\\n",
       "0       I'm on a seafood diet... I see food, and if it...   \n",
       "1       The shoe store... An Al Bundy one-liner:\\n\\nA ...   \n",
       "2       What do you say to a veteran prostitute after ...   \n",
       "3       Confused man sees a psychiatrist A man goes to...   \n",
       "4       Teabags have fought back! Humans have been ens...   \n",
       "...                                                   ...   \n",
       "962882  At 12:01 after midnight, on a cloudy evening, ...   \n",
       "962883  Two Gay guys are lying on their bed... Two gay...   \n",
       "962884  What do scientists use to measure a chicken's ...   \n",
       "962885  What is the only thing a woman can say that wi...   \n",
       "962886  I hope you're all getting your Walter Cronkite...   \n",
       "\n",
       "                                            word_tokenize  \\\n",
       "0       [I, 'm, on, a, seafood, diet, ..., I, see, foo...   \n",
       "1       [The, shoe, store, ..., An, Al, Bundy, one-lin...   \n",
       "2       [What, do, you, say, to, a, veteran, prostitut...   \n",
       "3       [Confused, man, sees, a, psychiatrist, A, man,...   \n",
       "4       [Teabags, have, fought, back, !, Humans, have,...   \n",
       "...                                                   ...   \n",
       "962882  [At, 12:01, after, midnight, ,, on, a, cloudy,...   \n",
       "962883  [Two, Gay, guys, are, lying, on, their, bed, ....   \n",
       "962884  [What, do, scientists, use, to, measure, a, ch...   \n",
       "962885  [What, is, the, only, thing, a, woman, can, sa...   \n",
       "962886  [I, hope, you, 're, all, getting, your, Walter...   \n",
       "\n",
       "                                            sent_tokenize  \n",
       "0       [I'm on a seafood diet..., I see food, and if ...  \n",
       "1       [The shoe store... An Al Bundy one-liner:\\n\\nA...  \n",
       "2       [What do you say to a veteran prostitute after...  \n",
       "3       [Confused man sees a psychiatrist A man goes t...  \n",
       "4       [Teabags have fought back!, Humans have been e...  \n",
       "...                                                   ...  \n",
       "962882  [At 12:01 after midnight, on a cloudy evening,...  \n",
       "962883  [Two Gay guys are lying on their bed... Two ga...  \n",
       "962884  [What do scientists use to measure a chicken's...  \n",
       "962885  [What is the only thing a woman can say that w...  \n",
       "962886  [I hope you're all getting your Walter Cronkit...  \n",
       "\n",
       "[962887 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jokes = {}\n",
    "\n",
    "for i, row in jokes.iterrows():\n",
    "    joke = row['joke']\n",
    "    if \"?\" in joke:\n",
    "        new_jokes[i] = {'text': joke, 'word_tokenize': row['word_tokenize'], 'sent_tokenize': row['sent_tokenize']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_jokes = pd.DataFrame(new_jokes).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you say to a veteran prostitute after ...</td>\n",
       "      <td>[What, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>[What do you say to a veteran prostitute after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Why didn't the chicken cross the road ???  .  ...</td>\n",
       "      <td>[Why, did, n't, the, chicken, cross, the, road...</td>\n",
       "      <td>[Why didn't the chicken cross the road ???, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What starts with E, ends with E, and has only ...</td>\n",
       "      <td>[What, starts, with, E, ,, ends, with, E, ,, a...</td>\n",
       "      <td>[What starts with E, ends with E, and has only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "2  What do you say to a veteran prostitute after ...   \n",
       "4  Teabags have fought back! Humans have been ens...   \n",
       "5  Why didn't the chicken cross the road ???  .  ...   \n",
       "6  What starts with E, ends with E, and has only ...   \n",
       "7  Teabags have fought back! Humans have been ens...   \n",
       "\n",
       "                                       word_tokenize  \\\n",
       "2  [What, do, you, say, to, a, veteran, prostitut...   \n",
       "4  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "5  [Why, did, n't, the, chicken, cross, the, road...   \n",
       "6  [What, starts, with, E, ,, ends, with, E, ,, a...   \n",
       "7  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "\n",
       "                                       sent_tokenize  \n",
       "2  [What do you say to a veteran prostitute after...  \n",
       "4  [Teabags have fought back!, Humans have been e...  \n",
       "5  [Why didn't the chicken cross the road ???, .,...  \n",
       "6  [What starts with E, ends with E, and has only...  \n",
       "7  [Teabags have fought back!, Humans have been e...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518458, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_jokes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_jokes.index = list(range(question_jokes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What do you say to a veteran prostitute after ...</td>\n",
       "      <td>[What, do, you, say, to, a, veteran, prostitut...</td>\n",
       "      <td>[What do you say to a veteran prostitute after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why didn't the chicken cross the road ???  .  ...</td>\n",
       "      <td>[Why, did, n't, the, chicken, cross, the, road...</td>\n",
       "      <td>[Why didn't the chicken cross the road ???, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What starts with E, ends with E, and has only ...</td>\n",
       "      <td>[What, starts, with, E, ,, ends, with, E, ,, a...</td>\n",
       "      <td>[What starts with E, ends with E, and has only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teabags have fought back! Humans have been ens...</td>\n",
       "      <td>[Teabags, have, fought, back, !, Humans, have,...</td>\n",
       "      <td>[Teabags have fought back!, Humans have been e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  What do you say to a veteran prostitute after ...   \n",
       "1  Teabags have fought back! Humans have been ens...   \n",
       "2  Why didn't the chicken cross the road ???  .  ...   \n",
       "3  What starts with E, ends with E, and has only ...   \n",
       "4  Teabags have fought back! Humans have been ens...   \n",
       "\n",
       "                                       word_tokenize  \\\n",
       "0  [What, do, you, say, to, a, veteran, prostitut...   \n",
       "1  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "2  [Why, did, n't, the, chicken, cross, the, road...   \n",
       "3  [What, starts, with, E, ,, ends, with, E, ,, a...   \n",
       "4  [Teabags, have, fought, back, !, Humans, have,...   \n",
       "\n",
       "                                       sent_tokenize  \n",
       "0  [What do you say to a veteran prostitute after...  \n",
       "1  [Teabags have fought back!, Humans have been e...  \n",
       "2  [Why didn't the chicken cross the road ???, .,...  \n",
       "3  [What starts with E, ends with E, and has only...  \n",
       "4  [Teabags have fought back!, Humans have been e...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "jokes\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "datas = {}\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words.extend([\"...\", \"'s\", \"wo\", \"n't\", \"'m\", \"ca\", \"'ll\", \"'re\", \"'ve\", \"'d\", \"ha\", \"Â´Â´\", \"Â´\", \"Â´Â´Â´\", \",\", \"!\", \"?\", \"'\", \":\", \";\", '\"', \"\\\\\", \"``\"])\n",
    "\n",
    "all_lem_data = []\n",
    "for name, data, n in zip(['qa', 'jokes'], [qa, question_jokes], [100000, 100000]):\n",
    "    print(name, end=\"\\n\")\n",
    "    lemmatized_data = []\n",
    "    for i, row in data.iterrows():\n",
    "        if i == n:\n",
    "            break\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        '''text = row[\"text\"]\n",
    "        for ajaleht in ajalehed:\n",
    "            text = re.sub(ajaleht, \"\", text)\n",
    "        \n",
    "        words = word_tokenize(text)'''\n",
    "        \n",
    "        words = row['word_tokenize']\n",
    "        lemmas = []\n",
    "\n",
    "        for word in words:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            if len(lemma) > 1 and not lemma in stop_words:\n",
    "                lemmas.append(lemma.lower())\n",
    "                \n",
    "        lemmatized_row = {'id': f\"{name}_{i}\",'text': \" \".join(lemmas), 'joke': 1 if name == 'jokes' else 0}\n",
    "        lemmatized_data.append(lemmatized_row)\n",
    "        all_lem_data.append(lemmatized_row)\n",
    "    \n",
    "    datas[name] = pd.DataFrame(lemmatized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"wa\", \"''\", \"the\", \"he\", \"my\", \"it\"]\n",
    "\n",
    "data_for_df = []\n",
    "\n",
    "jokes = list(datas['jokes'].text)\n",
    "ids = list(datas['jokes'].id)\n",
    "\n",
    "for i, joke in enumerate(jokes):\n",
    "    joke_words = joke.split(\" \")\n",
    "    joke_words = [word for word in joke_words if word not in stopwords and word.isalpha()]\n",
    "    joke_text = \" \".join(joke_words)\n",
    "    data_for_df.append({'id': ids[i], 'text': joke_text, 'joke': 1})\n",
    "    \n",
    "qa = list(datas['qa'].text)\n",
    "qa_ids = list(datas['qa'].id)\n",
    "\n",
    "for i, q in enumerate(qa):\n",
    "    qa_words = q.split(\" \")\n",
    "    qa_words = [word for word in qa_words if word not in stopwords and word.isalpha()]\n",
    "    qa_text = \" \".join(qa_words)\n",
    "    data_for_df.append({'id': qa_ids[i], 'text': qa_text, 'joke': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jokes_0</td>\n",
       "      <td>what say veteran prostitute night together tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jokes_1</td>\n",
       "      <td>teabags fought back humans enslaved civilizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jokes_2</td>\n",
       "      <td>why chicken cross road kfc side</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jokes_3</td>\n",
       "      <td>what start end letter envelope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jokes_4</td>\n",
       "      <td>teabags fought back humans enslaved civilizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>qa_99995</td>\n",
       "      <td>channel audience network comcast directv nbc s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>qa_99996</td>\n",
       "      <td>doe crisis shakespearean romance occur shakesp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>qa_99997</td>\n",
       "      <td>play henry mill upon time henry daniel mills f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>qa_99998</td>\n",
       "      <td>name body orbit around sun small solar system ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>qa_99999</td>\n",
       "      <td>played blind girl fantastic four alicia blind ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  joke\n",
       "0        jokes_0  what say veteran prostitute night together tha...     1\n",
       "1        jokes_1  teabags fought back humans enslaved civilizati...     1\n",
       "2        jokes_2                    why chicken cross road kfc side     1\n",
       "3        jokes_3                     what start end letter envelope     1\n",
       "4        jokes_4  teabags fought back humans enslaved civilizati...     1\n",
       "...          ...                                                ...   ...\n",
       "199995  qa_99995  channel audience network comcast directv nbc s...     0\n",
       "199996  qa_99996  doe crisis shakespearean romance occur shakesp...     0\n",
       "199997  qa_99997  play henry mill upon time henry daniel mills f...     0\n",
       "199998  qa_99998  name body orbit around sun small solar system ...     0\n",
       "199999  qa_99999  played blind girl fantastic four alicia blind ...     0\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB\n",
    "Tee baasiks lihtne mudel, et selle pÃµhjal (feature weights?) vaadata, mille jÃ¤rgi mudel ennustab, mis on nali, mis ei ole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_subdf = df[df['joke'] == 1].head(25000)\n",
    "qa_subdf = df[df['joke'] == 0].head(25000)\n",
    "\n",
    "smaller_df = pd.concat([jokes_subdf, qa_subdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jokes_0</td>\n",
       "      <td>what say veteran prostitute night together tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jokes_1</td>\n",
       "      <td>teabags fought back humans enslaved civilizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jokes_2</td>\n",
       "      <td>why chicken cross road kfc side</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jokes_3</td>\n",
       "      <td>what start end letter envelope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jokes_4</td>\n",
       "      <td>teabags fought back humans enslaved civilizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124995</th>\n",
       "      <td>qa_24995</td>\n",
       "      <td>michael jordan point game points game overtime...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124996</th>\n",
       "      <td>qa_24996</td>\n",
       "      <td>sang highest number song india playback singer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124997</th>\n",
       "      <td>qa_24997</td>\n",
       "      <td>doe new raven home come pilot series announced...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124998</th>\n",
       "      <td>qa_24998</td>\n",
       "      <td>got evicted tonight big brother on finale nigh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124999</th>\n",
       "      <td>qa_24999</td>\n",
       "      <td>movie ghost mississippi filmed medgar evers bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  joke\n",
       "0        jokes_0  what say veteran prostitute night together tha...     1\n",
       "1        jokes_1  teabags fought back humans enslaved civilizati...     1\n",
       "2        jokes_2                    why chicken cross road kfc side     1\n",
       "3        jokes_3                     what start end letter envelope     1\n",
       "4        jokes_4  teabags fought back humans enslaved civilizati...     1\n",
       "...          ...                                                ...   ...\n",
       "124995  qa_24995  michael jordan point game points game overtime...     0\n",
       "124996  qa_24996  sang highest number song india playback singer...     0\n",
       "124997  qa_24997  doe new raven home come pilot series announced...     0\n",
       "124998  qa_24998  got evicted tonight big brother on finale nigh...     0\n",
       "124999  qa_24999  movie ghost mississippi filmed medgar evers bl...     0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(smaller_df['text'], smaller_df['joke'], test_size=0.2, stratify=smaller_df['joke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: joke, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jokes as positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mnb.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9747"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.74403441, -12.17341482, -12.18063643, ..., -11.96578671,\n",
       "        -11.96578671, -11.87784092]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is from: https://stackoverflow.com/questions/29867367/sklearn-multinomial-nb-most-informative-features\n",
    "\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        #print (round(coef_1, 2), fn_1, \"\\t\\t\", round(coef_2, 2), fn_2)\n",
    "        print (round(coef_2, 2), fn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.19 what\n",
      "-5.81 why\n",
      "-5.96 say\n",
      "-6.07 call\n",
      "-6.26 how\n",
      "-6.27 man\n",
      "-6.33 because\n",
      "-6.34 get\n",
      "-6.55 know\n",
      "-6.57 doe\n",
      "-6.58 one\n",
      "-6.69 said\n",
      "-6.74 you\n",
      "-6.75 go\n",
      "-6.77 guy\n",
      "-6.78 joke\n",
      "-6.83 they\n",
      "-6.85 like\n",
      "-7.03 asks\n",
      "-7.05 wife\n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125333"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnb.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-joke as positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vect, [abs(val-1) for val in y_train.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mnb.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results == [abs(val-1) for val in y_test.values]) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.86 song\n",
      "-6.86 first\n",
      "-6.87 season\n",
      "-6.91 in\n",
      "-6.95 united\n",
      "-7.0 new\n",
      "-7.08 film\n",
      "-7.1 state\n",
      "-7.11 series\n",
      "-7.13 also\n",
      "-7.16 year\n",
      "-7.2 one\n",
      "-7.21 world\n",
      "-7.24 states\n",
      "-7.24 may\n",
      "-7.25 time\n",
      "-7.26 episode\n",
      "-7.29 american\n",
      "-7.43 doe\n",
      "-7.44 game\n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(vectorizer, mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15000\n",
    "maxlen = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "tokenized_X_train = tokenizer.texts_to_sequences(X_train)\n",
    "tokenized_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(tokenized_X_train, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(tokenized_X_test, maxlen=X_train_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vec = to_categorical(y_train)\n",
    "y_test_vec = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 500) (10000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pad.shape, X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 64)           960000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 35)                14000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 72        \n",
      "=================================================================\n",
      "Total params: 974,072\n",
      "Trainable params: 974,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=num_words, input_length=X_train_pad.shape[1], output_dim=64))\n",
    "model.add(layers.LSTM(35))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 267s 7ms/sample - loss: 0.1754 - accuracy: 0.9447 - val_loss: 0.0476 - val_accuracy: 0.9850\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 295s 7ms/sample - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.0419 - val_accuracy: 0.9875\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 282s 7ms/sample - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.0446 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e7fbed588>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train_vec, validation_data=(X_test_pad, y_test_vec), epochs=3, verbose=1, batch_size=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
