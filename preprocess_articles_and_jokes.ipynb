{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Birgit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_json(\"data/articles.json.xz\")\n",
    "jokes = pd.read_json(\"data/jokes.json.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajalehed = [\"Washington Post\", \"The New York Times\", \"Reuters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' reported on Thursday that  Trump backed down from his order after the White House counsel threatened to resign rather than follow his directive, citing four people told of the matter. “Fake news, folks, fake news,” Trump told reporters in Davos, when asked about the report. Reporting by Steve Holland'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"The New York Times\", \"\", 'The New York Times reported on Thursday that The New York Times Trump backed down from his order after the White House counsel threatened to resign rather than follow his directive, citing four people told of the matter. “Fake news, folks, fake news,” Trump told reporters in Davos, when asked about the report. Reporting by Steve Holland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jokes = {}\n",
    "\n",
    "for i, row in jokes.iterrows():\n",
    "    joke = row['text']\n",
    "    if \"?\" not in joke:\n",
    "        new_jokes[i] = {'text': joke}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_question_jokes = pd.DataFrame(new_jokes).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360085, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_question_jokes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "jokes\n",
      "0\n",
      "10000\n",
      "40000\n",
      "50000\n",
      "90000\n",
      "110000\n",
      "130000\n",
      "140000\n",
      "170000\n",
      "190000\n",
      "230000\n",
      "240000\n",
      "260000\n",
      "270000\n",
      "290000\n",
      "300000\n",
      "340000\n",
      "370000\n",
      "390000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "460000\n",
      "480000\n",
      "510000\n",
      "520000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "610000\n",
      "630000\n",
      "690000\n",
      "720000\n",
      "760000\n"
     ]
    }
   ],
   "source": [
    "datas = {}\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words.extend([\"...\", \"'s\", \"wo\", \"n't\", \"'m\", \"ca\", \"'ll\", \"'re\", \"'ve\", \"'d\", \"ha\", \"´´\", \"´\", \"´´´\", \",\", \"!\", \"?\", \"'\", \":\", \";\", '\"', \"\\\\\", \"``\"])\n",
    "\n",
    "all_lem_data = []\n",
    "for name, data, n in zip(['articles', 'jokes'], [articles, non_question_jokes], [100000, 100000]):\n",
    "    print(name, end=\"\\n\")\n",
    "    lemmatized_data = []\n",
    "    for i, row in data.iterrows():\n",
    "        if i == n:\n",
    "            break\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        text = row['text']\n",
    "        for ajaleht in ajalehed:\n",
    "            text = re.sub(ajaleht, \"\", text)\n",
    "        \n",
    "        words = word_tokenize(text)\n",
    "        lemmas = []\n",
    "\n",
    "        for word in words:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            if len(lemma) > 1 and not lemma in stop_words:\n",
    "                lemmas.append(lemma.lower())\n",
    "                \n",
    "        lemmatized_row = {'id': f\"{name}_{i}\",'text': \" \".join(lemmas), 'joke': 1 if name == 'jokes' else 0}\n",
    "        lemmatized_data.append(lemmatized_row)\n",
    "        all_lem_data.append(lemmatized_row)\n",
    "    \n",
    "    datas[name] = pd.DataFrame(lemmatized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_jokes = list(datas['jokes'][:100000].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_jokes = []\n",
    "\n",
    "for joke in lemmatized_jokes:\n",
    "    lemmas_jokes.extend(joke.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_articles = list(datas['articles'].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_articles = []\n",
    "\n",
    "for article in lemmatized_articles:\n",
    "    lemmas_articles.extend(article.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6636431"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmas_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"wa\", \"''\", \"the\", \"he\", \"my\", \"it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_articles = [lemma for lemma in lemmas_articles if lemma not in stopwords and lemma.isalpha()]\n",
    "lemmas_jokes = [lemma for lemma in lemmas_jokes if lemma not in stopwords and lemma.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_jokes = Counter(lemmas_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 15877),\n",
       " ('one', 14062),\n",
       " ('man', 13241),\n",
       " ('said', 12493),\n",
       " ('like', 11611),\n",
       " ('get', 11392),\n",
       " ('go', 9380),\n",
       " ('joke', 8716),\n",
       " ('day', 8327),\n",
       " ('got', 8240),\n",
       " ('time', 7636),\n",
       " ('people', 7221),\n",
       " ('wife', 7215),\n",
       " ('guy', 6571),\n",
       " ('they', 6505),\n",
       " ('know', 6404),\n",
       " ('you', 6282),\n",
       " ('told', 6101),\n",
       " ('would', 5982),\n",
       " ('but', 5937)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_jokes.most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_articles = Counter(lemmas_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 106761),\n",
       " ('year', 33481),\n",
       " ('would', 29712),\n",
       " ('percent', 26549),\n",
       " ('trump', 25108),\n",
       " ('company', 23870),\n",
       " ('last', 21266),\n",
       " ('reporting', 20534),\n",
       " ('new', 19794),\n",
       " ('also', 19651),\n",
       " ('editing', 18326),\n",
       " ('president', 17993),\n",
       " ('two', 17623),\n",
       " ('million', 17593),\n",
       " ('told', 17390),\n",
       " ('government', 17276),\n",
       " ('billion', 17045),\n",
       " ('bank', 16516),\n",
       " ('one', 15653),\n",
       " ('market', 15596)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_articles.most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in lemmas_articles:\n",
    "    if not word.isalpha():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final preprocessing of jokes and articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jokes_0</td>\n",
       "      <td>seafood diet see food fish eat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jokes_1</td>\n",
       "      <td>the shoe store an al bundy one-liner fat woman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jokes_3</td>\n",
       "      <td>confused man see psychiatrist man go see psych...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jokes_8</td>\n",
       "      <td>feel like fluffy white cloud azure blue sky high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jokes_10</td>\n",
       "      <td>stalin said dark humor like food not everyone get</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  joke\n",
       "0   jokes_0                     seafood diet see food fish eat     1\n",
       "1   jokes_1  the shoe store an al bundy one-liner fat woman...     1\n",
       "2   jokes_3  confused man see psychiatrist man go see psych...     1\n",
       "3   jokes_8   feel like fluffy white cloud azure blue sky high     1\n",
       "4  jokes_10  stalin said dark humor like food not everyone get     1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas['jokes'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_df = []\n",
    "\n",
    "jokes = list(datas['jokes'][:100000].text)\n",
    "ids = list(datas['jokes'][:100000].id)\n",
    "\n",
    "for i, joke in enumerate(jokes):\n",
    "    joke_words = joke.split(\" \")\n",
    "    joke_words = [word for word in joke_words if word not in stopwords and word.isalpha()]\n",
    "    joke_text = \" \".join(joke_words)\n",
    "    data_for_df.append({'id': ids[i], 'text': joke_text, 'joke': 1})\n",
    "    \n",
    "articles = list(datas['articles'].text)\n",
    "article_ids = list(datas['articles'].id)\n",
    "\n",
    "for i, article in enumerate(articles):\n",
    "    article_words = article.split(\" \")\n",
    "    article_words = [word for word in article_words if word not in stopwords and word.isalpha()]\n",
    "    article_text = \" \".join(article_words)\n",
    "    atricle_text = re.sub(\"reporting .*\", \"\", article_text)\n",
    "    data_for_df.append({'id': article_ids[i], 'text': article_text, 'joke': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jokes_0</td>\n",
       "      <td>seafood diet see food fish eat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jokes_1</td>\n",
       "      <td>shoe store an al bundy fat woman came shoe sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jokes_3</td>\n",
       "      <td>confused man see psychiatrist man go see psych...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jokes_8</td>\n",
       "      <td>feel like fluffy white cloud azure blue sky high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jokes_10</td>\n",
       "      <td>stalin said dark humor like food not everyone get</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>articles_99995</td>\n",
       "      <td>group lawmaker heart logjam said backed aoun e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>articles_99996</td>\n",
       "      <td>sale would give pwc freer hand pursue growing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>articles_99997</td>\n",
       "      <td>pressure building company almost two year defe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>articles_99998</td>\n",
       "      <td>strong earnings season would help justify pric...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>articles_99999</td>\n",
       "      <td>below list date european defence cooperation u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0              jokes_0                     seafood diet see food fish eat   \n",
       "1              jokes_1  shoe store an al bundy fat woman came shoe sto...   \n",
       "2              jokes_3  confused man see psychiatrist man go see psych...   \n",
       "3              jokes_8   feel like fluffy white cloud azure blue sky high   \n",
       "4             jokes_10  stalin said dark humor like food not everyone get   \n",
       "...                ...                                                ...   \n",
       "199995  articles_99995  group lawmaker heart logjam said backed aoun e...   \n",
       "199996  articles_99996  sale would give pwc freer hand pursue growing ...   \n",
       "199997  articles_99997  pressure building company almost two year defe...   \n",
       "199998  articles_99998  strong earnings season would help justify pric...   \n",
       "199999  articles_99999  below list date european defence cooperation u...   \n",
       "\n",
       "        joke  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "199995     0  \n",
       "199996     0  \n",
       "199997     0  \n",
       "199998     0  \n",
       "199999     0  \n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['joke'], test_size=0.05, stratify=df['joke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: joke, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15000\n",
    "#maxlen = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X_train[:10000])\n",
    "\n",
    "tokenized_X_train = tokenizer.texts_to_sequences(X_train[:10000])\n",
    "tokenized_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(tokenized_X_train)\n",
    "X_test_pad = pad_sequences(tokenized_X_test, maxlen=X_train_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vec = to_categorical(y_train[:10000])\n",
    "y_test_vec = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 594)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 594)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 594, 64)           960000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 35)                14000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 72        \n",
      "=================================================================\n",
      "Total params: 974,072\n",
      "Trainable params: 974,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=num_words, input_length=X_train_pad.shape[1], output_dim=64))\n",
    "model.add(layers.LSTM(35))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 422s 42ms/sample - loss: 0.6800 - accuracy: 0.7823 - val_loss: 0.6548 - val_accuracy: 0.9535\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 442s 44ms/sample - loss: 0.6074 - accuracy: 0.9186 - val_loss: 0.5184 - val_accuracy: 0.8770\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 541s 54ms/sample - loss: 0.4343 - accuracy: 0.8632 - val_loss: 0.3344 - val_accuracy: 0.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x124b9ab3b08>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train_vec, validation_data=(X_test_pad, y_test_vec), epochs=3, verbose=1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15000\n",
    "#maxlen = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "tokenized_X_train = tokenizer.texts_to_sequences(X_train)\n",
    "tokenized_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(tokenized_X_train)\n",
    "X_test_pad = pad_sequences(tokenized_X_test, maxlen=X_train_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vec = to_categorical(y_train)\n",
    "y_test_vec = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3835, 64)          960000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 35)                14000     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 72        \n",
      "=================================================================\n",
      "Total params: 974,072\n",
      "Trainable params: 974,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Embedding(input_dim=num_words, input_length=X_train_pad.shape[1], output_dim=64))\n",
    "model2.add(layers.LSTM(35))\n",
    "model2.add(layers.Dense(2, activation='softmax'))\n",
    "model2.summary()\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      " 13440/190000 [=>............................] - ETA: 5:53:11 - loss: 0.1642 - accuracy: 0.9578"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-86585bb033b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Py3_ICNS_keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.fit(X_train_pad, y_train_vec, validation_data=(X_test_pad, y_test_vec), epochs=3, verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting = 0\n",
    "\n",
    "for i, t in enumerate(datas['articles'].text):\n",
    "    if \"reporting \" in t:\n",
    "        #print(t)\n",
    "        #print(\"-----------------------------------\")\n",
    "        reporting += 1\n",
    "    #if i == 100:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20248"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reported thursday trump backed order white house counsel threatened resign rather follow directive citing four people told matter fake news folk fake news trump told reporter davos asked report reporting steve holland\n",
      "\n",
      "\n",
      "reported thursday trump backed order white house counsel threatened resign rather follow directive citing four people told matter fake news folk fake news trump told reporter davos asked report \n",
      "-----------------------------------\n",
      "so-called tiered deposit rate would mean bank exempted part paying ecb 0.40 percent annual charge excess reserve boosting profit struggle unexpected growth slowdown we would consider whether tiering system needed coeure said interview financial times today prevailing view governing council also agree deserves reflection. reporting michelle martin editing tassilo hummel\n",
      "\n",
      "\n",
      "so-called tiered deposit rate would mean bank exempted part paying ecb 0.40 percent annual charge excess reserve boosting profit struggle unexpected growth slowdown we would consider whether tiering system needed coeure said interview financial times today prevailing view governing council also agree deserves reflection. \n",
      "-----------------------------------\n",
      "may offered quit return support conservative lawmaker deal focused getting parliament spokesman said adding continued believe agreement wa best available reporting william james writing elizabeth piper editing kylie maclellan\n",
      "\n",
      "\n",
      "may offered quit return support conservative lawmaker deal focused getting parliament spokesman said adding continued believe agreement wa best available \n",
      "-----------------------------------\n",
      "divisions remain among bloc 28 government long-term net-zero emission target many concerned steeper pace reduction could hurt competitiveness cost job high-employment sector reporting andreas rinke writing michelle martin editing thomas escritt\n",
      "\n",
      "\n",
      "divisions remain among bloc 28 government long-term net-zero emission target many concerned steeper pace reduction could hurt competitiveness cost job high-employment sector \n",
      "-----------------------------------\n",
      "barring last-minute decision russia destroy new medium-range missile nato say violates inf united states set pull accord aug. arguing need develop warhead deter moscow moscow say fully compliant inf treaty negotiated u.s. president ronald reagan soviet leader mikhail gorbachev eliminated medium-range missile arsenal world two biggest nuclear power we seen sign breakthrough stoltenberg told reporter meeting nato-russia council closed-door forum allows dialogue two side diplomat official stoltenberg said chance resolution going day day nato given trying convince moscow destroy ssc-8 ground-launched cruise missile say treaty ban land-based missile range 500 km 5,500 km 300-3,400 mile the breakdown treaty latest growing list east-west tension grave concern medium-range rocket would allow russia launch nuclear attack europe short notice western expert official say reporting robin emmott editing kevin liffey\n",
      "\n",
      "\n",
      "barring last-minute decision russia destroy new medium-range missile nato say violates inf united states set pull accord aug. arguing need develop warhead deter moscow moscow say fully compliant inf treaty negotiated u.s. president ronald reagan soviet leader mikhail gorbachev eliminated medium-range missile arsenal world two biggest nuclear power we seen sign breakthrough stoltenberg told reporter meeting nato-russia council closed-door forum allows dialogue two side diplomat official stoltenberg said chance resolution going day day nato given trying convince moscow destroy ssc-8 ground-launched cruise missile say treaty ban land-based missile range 500 km 5,500 km 300-3,400 mile the breakdown treaty latest growing list east-west tension grave concern medium-range rocket would allow russia launch nuclear attack europe short notice western expert official say \n",
      "-----------------------------------\n",
      "u.s. secretary state mike pompeo issued pre-emptive warning iran earlier thursday pursuing three planned space rocket launch said would violate u.n. security council resolution use ballistic missile technology iran launch space vehicle missile test not violation resolution 2231 the us material breach position lecture anyone zarif wrote english twitter reporting dubai newsroom editing andrew heavens\n",
      "\n",
      "\n",
      "u.s. secretary state mike pompeo issued pre-emptive warning iran earlier thursday pursuing three planned space rocket launch said would violate u.n. security council resolution use ballistic missile technology iran launch space vehicle missile test not violation resolution 2231 the us material breach position lecture anyone zarif wrote english twitter \n",
      "-----------------------------------\n",
      "huawei consumer business group smartphone product line president he gang revealed number launch event wuhan china new nova phone the phone powered huawei new 7-nanometer chipset kirin 810 huawei hit devastating curb ordered washington threatens cripple supply chain founder chief executive ren zhengfei said monday ban could cost company 30 billion revenue year smartphone sale outside china already dropped 40 percent past month reporting sijia jiang editing muralikumar anantharaman\n",
      "\n",
      "\n",
      "huawei consumer business group smartphone product line president he gang revealed number launch event wuhan china new nova phone the phone powered huawei new 7-nanometer chipset kirin 810 huawei hit devastating curb ordered washington threatens cripple supply chain founder chief executive ren zhengfei said monday ban could cost company 30 billion revenue year smartphone sale outside china already dropped 40 percent past month \n",
      "-----------------------------------\n",
      "reporting pushkala aripaka bengaluru editing bernard orr\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "dozens supporter martin fayulu gathered outside kinshasa hotel residence chanting slogan outgoing president joseph kabila president-elect felix tshisekedi fled inside building security force arrived witness said reporting by stanis bujakera writing aaron ross editing mark heinrich\n",
      "\n",
      "\n",
      "dozens supporter martin fayulu gathered outside kinshasa hotel residence chanting slogan outgoing president joseph kabila president-elect felix tshisekedi fled inside building security force arrived witness said \n",
      "-----------------------------------\n",
      "having left meeting canada early u.s. president donald trump said wa backing group joint declaration sinking appeared fragile consensus trade dispute washington top ally the commotion g7 summit canada brought european union closer together it important show unity level peter altmaier said arrival meeting eu minister luxembourg reporting robert-jan bartunek editing john stonestreet\n",
      "\n",
      "\n",
      "having left meeting canada early u.s. president donald trump said wa backing group joint declaration sinking appeared fragile consensus trade dispute washington top ally the commotion g7 summit canada brought european union closer together it important show unity level peter altmaier said arrival meeting eu minister luxembourg \n",
      "-----------------------------------\n",
      "we remain firmly committed one china policy said ned price national security spokesman president barack obama our fundamental interest peaceful stable cross-strait relations. reporting jeff mason editing sandra maler\n",
      "\n",
      "\n",
      "we remain firmly committed one china policy said ned price national security spokesman president barack obama our fundamental interest peaceful stable cross-strait relations. \n",
      "-----------------------------------\n",
      "what trying succeeding cut export revenue they sell oil sell petrochemiclas sell iron steel navarro said interview fox news it certainly working working beautifully. reporting david alexander susan heavey writing doina chiacu\n",
      "\n",
      "\n",
      "what trying succeeding cut export revenue they sell oil sell petrochemiclas sell iron steel navarro said interview fox news it certainly working working beautifully. \n",
      "-----------------------------------\n",
      "roche said monday company received request information u.s. federal trade commission connection ftc review deal sending spark share nearly 15 93 premarket trading monday roche also said uk competition markets authority cma opened investigation roche want buy spark among thing get hold u.s. firm experimental gene therapy hemophilia well platform develop treatment genetic disease but roche forced push back completion repeatedly time giving july 31 beyond self-imposed first-half deadline wrap thing the party remain committed transaction working cooperatively expeditiously ftc connection review roche said statement the ftc said doe comment case reviewing the british regulator separate inquiry aimed determining whether cma considers jurisdiction roche acquisition whether could hurt competition britain pending outcome investigation cma issued interim enforcement order would become effective upon closing transaction would require roche hold separate spark business roche said the party working cooperatively cma continue so. reporting john miller additional reporting tamara mathias editing himani sarkar anil d'silva\n",
      "\n",
      "\n",
      "roche said monday company received request information u.s. federal trade commission connection ftc review deal sending spark share nearly 15 93 premarket trading monday roche also said uk competition markets authority cma opened investigation roche want buy spark among thing get hold u.s. firm experimental gene therapy hemophilia well platform develop treatment genetic disease but roche forced push back completion repeatedly time giving july 31 beyond self-imposed first-half deadline wrap thing the party remain committed transaction working cooperatively expeditiously ftc connection review roche said statement the ftc said doe comment case reviewing the british regulator separate inquiry aimed determining whether cma considers jurisdiction roche acquisition whether could hurt competition britain pending outcome investigation cma issued interim enforcement order would become effective upon closing transaction would require roche hold separate spark business roche said the party working cooperatively cma continue so. \n",
      "-----------------------------------\n",
      "rouhani officially accepted zarif resignation announced instagram post the word president today praising foreign minister clear sign satisfaction representative people iran wise effective position work dr. zarif tough response biased incorrect analysis mahmoud vaezi wrote instagram post included picture rouhani zarif together in view dr. rouhani islamic republic iran one foreign policy one foreign minister. reporting by babak dehghanpisheh editing kevin liffey\n",
      "\n",
      "\n",
      "rouhani officially accepted zarif resignation announced instagram post the word president today praising foreign minister clear sign satisfaction representative people iran wise effective position work dr. zarif tough response biased incorrect analysis mahmoud vaezi wrote instagram post included picture rouhani zarif together in view dr. rouhani islamic republic iran one foreign policy one foreign minister. \n",
      "-----------------------------------\n",
      "signs growing tension united states china may good opportunity brazil given prowess produce grain like soy corn said carlos favaro mato grosso vice governor he added brazil expand commercial tie china noting bond steadily growing recent year china invested heavily brazil agribusiness sector infrastructure project reporting ana mano editing chizu nomiyama\n",
      "\n",
      "\n",
      "signs growing tension united states china may good opportunity brazil given prowess produce grain like soy corn said carlos favaro mato grosso vice governor he added brazil expand commercial tie china noting bond steadily growing recent year china invested heavily brazil agribusiness sector infrastructure project \n",
      "-----------------------------------\n",
      "the privacy security user extremely important this claim without merit pleased court dismissed google spokesperson said answer request comment google unit alphabet googl.o u.s. tech company reporting douglas busvine\n",
      "\n",
      "\n",
      "the privacy security user extremely important this claim without merit pleased court dismissed google spokesperson said answer request comment google unit alphabet googl.o u.s. tech company \n",
      "-----------------------------------\n",
      "discussions continue there clarity yet dmitry peskov wa quoted interfax saying the white house said friday trump separate meeting russian counterpart reporting maria kiselyova writing polina nikolskaya editing nick macfie\n",
      "\n",
      "\n",
      "discussions continue there clarity yet dmitry peskov wa quoted interfax saying the white house said friday trump separate meeting russian counterpart \n",
      "-----------------------------------\n",
      "the conservatives second-largest party scotland devolved government behind sturgeon scottish nationalists snp also send second-biggest number lawmaker british parliament 13 country 55 seat westminster may challenged european union come better solution so-called chequers proposal brexit rejected hand european summit thursday if may tactic double chequers dead duck blame eu deal huge damage supposed serve sturgeon said statement friday blaming eu no-deal would abdication responsibility huge historic proportion approach theresa may tory party would pay heavy political price especially scotland overwhelmingly rejected brexit added scotland one united kingdom four nation voted large margin remain eu june 2016 referendum although uk whole voted leave sturgeon support independence scotland accuses may party consistently ignoring scots wish brexit negotiation called keep britain eu single market reporting elisabeth o'leary editing stephen addison\n",
      "\n",
      "\n",
      "the conservatives second-largest party scotland devolved government behind sturgeon scottish nationalists snp also send second-biggest number lawmaker british parliament 13 country 55 seat westminster may challenged european union come better solution so-called chequers proposal brexit rejected hand european summit thursday if may tactic double chequers dead duck blame eu deal huge damage supposed serve sturgeon said statement friday blaming eu no-deal would abdication responsibility huge historic proportion approach theresa may tory party would pay heavy political price especially scotland overwhelmingly rejected brexit added scotland one united kingdom four nation voted large margin remain eu june 2016 referendum although uk whole voted leave sturgeon support independence scotland accuses may party consistently ignoring scots wish brexit negotiation called keep britain eu single market \n",
      "-----------------------------------\n",
      "europe must clearly commit path climate neutrality 2050 clean planet interest european commission vice president maros sefcovic told new eu assembly gathered following may election ass proposal allocating eu top job reporting robin emmott writing alissa de carbonnel\n",
      "\n",
      "\n",
      "europe must clearly commit path climate neutrality 2050 clean planet interest european commission vice president maros sefcovic told new eu assembly gathered following may election ass proposal allocating eu top job \n",
      "-----------------------------------\n",
      "british prime minister theresa may cabinet approved draft agreement wednesday face uncertain future uk parliament several may minister resigned deal thursday we think side exhausted margin maneuver respective mandate eu official said reporting gabriela baczynska editing janet lawrence\n",
      "\n",
      "\n",
      "british prime minister theresa may cabinet approved draft agreement wednesday face uncertain future uk parliament several may minister resigned deal thursday we think side exhausted margin maneuver respective mandate eu official said \n",
      "-----------------------------------\n",
      "asked lbc radio could vote may deal ensure britain leaf eu francois said no you hold nose holding hand air surrendering. what withdrawal agreement mean remain european union. reporting elisabeth o'leary editing guy faulconbridge\n",
      "\n",
      "\n",
      "asked lbc radio could vote may deal ensure britain leaf eu francois said no you hold nose holding hand air surrendering. what withdrawal agreement mean remain european union. \n",
      "-----------------------------------\n",
      "the decision engage discussion groupe renault‎ wa right one one took much preparation many front john elkann wrote letter elkann said decision end talk aimed protect interest company employee stakeholder become clear discussion taken far reasonably go. fca mike manley leadership outstanding business clear strategy strong independent future we continue open opportunity kind offer possibility enhance accelerate delivery strategy creation value wrote reporting valentina za editing francesca landini\n",
      "\n",
      "\n",
      "the decision engage discussion groupe renault‎ wa right one one took much preparation many front john elkann wrote letter elkann said decision end talk aimed protect interest company employee stakeholder become clear discussion taken far reasonably go. fca mike manley leadership outstanding business clear strategy strong independent future we continue open opportunity kind offer possibility enhance accelerate delivery strategy creation value wrote \n",
      "-----------------------------------\n",
      "the two leader widely expected hold first personal meeting attend g20 summit germany july anyway putin trump present event city time anyway possibility meeting putin spokesman dmitry peskov told conference call reporter let wait g20 summit but repeat regret far definite arrangement regarding meeting reporting dmitry solovyov editing vladimir soldatkin\n",
      "\n",
      "\n",
      "the two leader widely expected hold first personal meeting attend g20 summit germany july anyway putin trump present event city time anyway possibility meeting putin spokesman dmitry peskov told conference call reporter let wait g20 summit but repeat regret far definite arrangement regarding meeting \n",
      "-----------------------------------\n",
      "nguyen ngoc anh right peaceful freedom expression guaranteed vietnamese constitution. the southeast asian country government labeled anh post anti-state reporting alissa de carbonnel\n",
      "\n",
      "\n",
      "nguyen ngoc anh right peaceful freedom expression guaranteed vietnamese constitution. the southeast asian country government labeled anh post anti-state \n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(datas['articles'].text):\n",
    "    if \"reporting \" in t:\n",
    "        print(t)\n",
    "        print(\"\\n\")\n",
    "        print(re.sub(\"reporting .*\", \"\", t))\n",
    "        print(\"-----------------------------------\")\n",
    "    if i == 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
